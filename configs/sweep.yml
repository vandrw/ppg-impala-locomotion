program: src.sweep_mpi
method: bayes
metric:
  name: info.total_reward
  goal: maximize
parameters:
  env:
    value: healthy
  run_name:
    value: sweep
  log_wandb:
    value: "true"
  visualize:
    value: "false"
  train_mode:
    value: "true"
  PPO_epochs:
    distribution: int_uniform
    min: 5
    max: 20
  n_update:
    distribution: int_uniform
    min: 1000
    max: 10000
  n_aux_update:
    distribution: int_uniform
    min: 2
    max: 20
  batch_size:
    distribution: int_uniform
    min: 16
    max: 64
  lam:
    distribution: uniform
    min: 0.3
    max: 0.99
  gamma:
    distribution: uniform
    min: 0.3
    max: 0.99
  value_clip:
    distribution: uniform
    min: 0.5
    max: 2.0
  vf_loss_coef:
    distribution: uniform
    min: 0.5
    max: 2.0
  learning_rate:
    distribution: uniform
    min: 0.000125
    max: 0.001
  policy_params:
    distribution: uniform
    min: 2.5
    max: 10.0
  policy_kl_range:
    distribution: uniform
    min: 0.01
    max: 0.06
  entropy_coef:
    distribution: uniform
    min: 0.0
    max: 0.1
command:
  - mpirun
  - "--mca opal_warn_on_missing_libcuda 0"
  - python
  - "-m"
  - ${program}
  - ${args}